{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c495d9b",
   "metadata": {
    "papermill": {
     "duration": 0.010276,
     "end_time": "2021-08-25T10:42:47.766091",
     "exception": false,
     "start_time": "2021-08-25T10:42:47.755815",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Brain Tumor Segmentation BRATS2021**\n",
    "\n",
    "Loading classes for segmentation from Brats 2020:\n",
    "\n",
    "-[1] https://www.kaggle.com/frlemarchand/brain-tumour-segmentation-in-mri-slices/\n",
    "\n",
    "-[2] https://www.kaggle.com/arashmehrzadi/brain-tumor-segmentation-unet/output\n",
    "\n",
    "\n",
    "***After testing the performance for segmentation the rsna data with [2], the accuracy is not working very well, so, we are trying to run the U-Net with Brats 2021 data, and finally doing the ensemble with 2020, and check again:\n",
    "\n",
    "- https://www.kaggle.com/dschettler8845/how-to-load-basic-data-exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69176c61",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-08-25T10:42:47.801061Z",
     "iopub.status.busy": "2021-08-25T10:42:47.800393Z",
     "iopub.status.idle": "2021-08-25T10:42:54.100559Z",
     "shell.execute_reply": "2021-08-25T10:42:54.099560Z",
     "shell.execute_reply.started": "2021-08-25T10:02:18.420211Z"
    },
    "papermill": {
     "duration": 6.325083,
     "end_time": "2021-08-25T10:42:54.100712",
     "exception": false,
     "start_time": "2021-08-25T10:42:47.775629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.layers import concatenate\n",
    "###Libraries and imports\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "import gzip\n",
    "import shutil\n",
    "import glob\n",
    "import gc\n",
    "import cv2 as cv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import PIL\n",
    "import scipy.misc\n",
    "import skimage\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from tensorflow import keras\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input ,BatchNormalization , Activation \n",
    "from keras.layers.convolutional import Conv2D, UpSampling2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import optimizers \n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.morphology import ball, disk, dilation, binary_erosion, remove_small_objects, erosion, closing, reconstruction, binary_closing\n",
    "from skimage.measure import label,regionprops, perimeter\n",
    "from skimage.morphology import binary_dilation, binary_opening\n",
    "from skimage.filters import roberts, sobel\n",
    "from skimage import measure, feature\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage import data\n",
    "from skimage.io import imread\n",
    "from scipy import ndimage as ndi\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "DEVICE = \"GPU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a0095e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T10:42:54.127346Z",
     "iopub.status.busy": "2021-08-25T10:42:54.126676Z",
     "iopub.status.idle": "2021-08-25T10:42:54.281107Z",
     "shell.execute_reply": "2021-08-25T10:42:54.280680Z",
     "shell.execute_reply.started": "2021-08-25T10:02:28.574804Z"
    },
    "papermill": {
     "duration": 0.170411,
     "end_time": "2021-08-25T10:42:54.281226",
     "exception": false,
     "start_time": "2021-08-25T10:42:54.110815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default strategy for CPU and single GPU\n",
      "Num GPUs Available:  0\n",
      "REPLICAS: 1\n"
     ]
    }
   ],
   "source": [
    "if DEVICE == \"TPU\":\n",
    "    print(\"connecting to TPU...\")\n",
    "    try:\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "        print('Running on TPU ', tpu.master())\n",
    "    except ValueError:\n",
    "        print(\"Could not connect to TPU\")\n",
    "        tpu = None\n",
    "\n",
    "    if tpu:\n",
    "        try:\n",
    "            print(\"initializing  TPU ...\")\n",
    "            tf.config.experimental_connect_to_cluster(tpu)\n",
    "            tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "            print(\"TPU initialized\")\n",
    "        except _:\n",
    "            print(\"failed to initialize TPU\")\n",
    "    else:\n",
    "        DEVICE = \"GPU\"\n",
    "\n",
    "if DEVICE != \"TPU\":\n",
    "    print(\"Using default strategy for CPU and single GPU\")\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "if DEVICE == \"GPU\":\n",
    "    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "    \n",
    "\n",
    "AUTO     = tf.data.experimental.AUTOTUNE\n",
    "REPLICAS = strategy.num_replicas_in_sync\n",
    "print(f'REPLICAS: {REPLICAS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64ebbb8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T10:42:54.325766Z",
     "iopub.status.busy": "2021-08-25T10:42:54.318248Z",
     "iopub.status.idle": "2021-08-25T10:42:56.260684Z",
     "shell.execute_reply": "2021-08-25T10:42:56.259923Z",
     "shell.execute_reply.started": "2021-08-25T10:02:28.602934Z"
    },
    "papermill": {
     "duration": 1.969776,
     "end_time": "2021-08-25T10:42:56.260825",
     "exception": false,
     "start_time": "2021-08-25T10:42:54.291049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Compiling the model with:  GPU\n"
     ]
    }
   ],
   "source": [
    "def Convolution(input_tensor,filters):\n",
    "    x = Conv2D(filters=filters,kernel_size=(3, 3),padding = 'same',strides=(1, 1))(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x) \n",
    "    return x\n",
    "\n",
    "def model(input_shape):\n",
    "    \n",
    "    inputs = Input((input_shape))\n",
    "    \n",
    "    conv_1 = Convolution(inputs,32)\n",
    "    maxp_1 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_1)\n",
    "    \n",
    "    conv_2 = Convolution(maxp_1,64)\n",
    "    maxp_2 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_2)\n",
    "    \n",
    "    conv_3 = Convolution(maxp_2,128)\n",
    "    maxp_3 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_3)\n",
    "    \n",
    "    conv_4 = Convolution(maxp_3,256)\n",
    "    maxp_4 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_4)\n",
    "    \n",
    "    conv_5 = Convolution(maxp_4,512)\n",
    "    upsample_6 = UpSampling2D((2, 2)) (conv_5)\n",
    "    \n",
    "    conv_6 = Convolution(upsample_6,256)\n",
    "    upsample_7 = UpSampling2D((2, 2)) (conv_6)\n",
    "    \n",
    "    upsample_7 = concatenate([upsample_7, conv_3])\n",
    "    \n",
    "    conv_7 = Convolution(upsample_7,128)\n",
    "    upsample_8 = UpSampling2D((2, 2)) (conv_7)\n",
    "    \n",
    "    conv_8 = Convolution(upsample_8,64)\n",
    "    upsample_9 = UpSampling2D((2, 2)) (conv_8)\n",
    "    \n",
    "    upsample_9 = concatenate([upsample_9, conv_1])\n",
    "    \n",
    "    conv_9 = Convolution(upsample_9,32)\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid') (conv_9)\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=[outputs]) \n",
    "    \n",
    "    return model\n",
    "\n",
    "# Computing Dice_Coefficient\n",
    "def dice_coef(y_true, y_pred, smooth=1.0):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "# Computing Precision \n",
    "def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "# Computing Sensitivity      \n",
    "def sensitivity(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "# Computing Specificity\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())\n",
    "\n",
    "# Accuracy vs Epoch\n",
    "def Accuracy_Graph(history):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    #plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,\n",
    "                        wspace=0.35)\n",
    "    plt.show()\n",
    "    \n",
    "# Dice Similarity Coefficient vs Epoch\n",
    "def Dice_coefficient_Graph(history):\n",
    "\n",
    "    plt.plot(history.history['dice_coef'])\n",
    "    plt.plot(history.history['val_dice_coef'])\n",
    "    #plt.title('Dice_Coefficient')\n",
    "    plt.ylabel('Dice_Coefficient')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,\n",
    "                        wspace=0.35)\n",
    "    plt.show()\n",
    "# Loss vs Epoch\n",
    "def Loss_Graph(history):\n",
    "\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    #plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,\n",
    "                        wspace=0.35)\n",
    "    plt.show()\n",
    "\n",
    "print(\"-- Compiling the model with: \", DEVICE)\n",
    "input_size = 240\n",
    "if DEVICE=='TPU':\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
    "    tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "    with tpu_strategy.scope():\n",
    "        model = model(input_shape = (input_size, input_size, 1))\n",
    "        Adam=optimizers.Adam(lr=0.001)\n",
    "        model.compile(optimizer=Adam, loss='binary_crossentropy', metrics=['accuracy',dice_coef,precision,sensitivity,specificity])        \n",
    "else:   \n",
    "    model = model(input_shape = (input_size, input_size, 1))\n",
    "    Adam=optimizers.Adam(lr=0.001)\n",
    "    model.compile(optimizer=Adam, loss='binary_crossentropy', metrics=['accuracy',dice_coef,precision,sensitivity,specificity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbe507dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T10:42:56.286212Z",
     "iopub.status.busy": "2021-08-25T10:42:56.285641Z",
     "iopub.status.idle": "2021-08-25T10:42:58.259452Z",
     "shell.execute_reply": "2021-08-25T10:42:58.258961Z",
     "shell.execute_reply.started": "2021-08-25T10:02:29.008790Z"
    },
    "papermill": {
     "duration": 1.98878,
     "end_time": "2021-08-25T10:42:58.259610",
     "exception": false,
     "start_time": "2021-08-25T10:42:56.270830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Der Befehl \"rm\" ist entweder falsch geschrieben oder\n",
      "konnte nicht gefunden werden.\n",
      "Der Befehl \"rm\" ist entweder falsch geschrieben oder\n",
      "konnte nicht gefunden werden.\n",
      "Der Befehl \"rm\" ist entweder falsch geschrieben oder\n",
      "konnte nicht gefunden werden.\n"
     ]
    }
   ],
   "source": [
    "!rm -Rf ./post_process_data\n",
    "!rm -Rf ./data\n",
    "!rm -Rf ./final_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a70ad269",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T10:42:58.311258Z",
     "iopub.status.busy": "2021-08-25T10:42:58.300745Z",
     "iopub.status.idle": "2021-08-25T10:45:57.777616Z",
     "shell.execute_reply": "2021-08-25T10:45:57.778267Z",
     "shell.execute_reply.started": "2021-08-25T10:03:59.038711Z"
    },
    "papermill": {
     "duration": 179.508019,
     "end_time": "2021-08-25T10:45:57.778472",
     "exception": false,
     "start_time": "2021-08-25T10:42:58.270453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/brats-2021-task1/BraTS2021_Training_Data.tar'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [16], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#!mkdir data\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m tar \u001B[38;5;241m=\u001B[39m \u001B[43mtarfile\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/kaggle/input/brats-2021-task1/BraTS2021_Training_Data.tar\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m tar\u001B[38;5;241m.\u001B[39mextractall(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.data\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      5\u001B[0m tar\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[1;32mC:\\Program Files\\Python310\\lib\\tarfile.py:1632\u001B[0m, in \u001B[0;36mTarFile.open\u001B[1;34m(cls, name, mode, fileobj, bufsize, **kwargs)\u001B[0m\n\u001B[0;32m   1630\u001B[0m     saved_pos \u001B[38;5;241m=\u001B[39m fileobj\u001B[38;5;241m.\u001B[39mtell()\n\u001B[0;32m   1631\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1632\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(name, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m, fileobj, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1633\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (ReadError, CompressionError) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1634\u001B[0m     error_msgs\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m- method \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcomptype\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32mC:\\Program Files\\Python310\\lib\\tarfile.py:1698\u001B[0m, in \u001B[0;36mTarFile.gzopen\u001B[1;34m(cls, name, mode, fileobj, compresslevel, **kwargs)\u001B[0m\n\u001B[0;32m   1695\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CompressionError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgzip module is not available\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m   1697\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1698\u001B[0m     fileobj \u001B[38;5;241m=\u001B[39m \u001B[43mGzipFile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcompresslevel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfileobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1699\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1700\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m fileobj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m:\n",
      "File \u001B[1;32mC:\\Program Files\\Python310\\lib\\gzip.py:174\u001B[0m, in \u001B[0;36mGzipFile.__init__\u001B[1;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001B[0m\n\u001B[0;32m    172\u001B[0m     mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    173\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fileobj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 174\u001B[0m     fileobj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmyfileobj \u001B[38;5;241m=\u001B[39m \u001B[43mbuiltins\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    175\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m filename \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    176\u001B[0m     filename \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(fileobj, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/kaggle/input/brats-2021-task1/BraTS2021_Training_Data.tar'"
     ]
    }
   ],
   "source": [
    "#!mkdir data\n",
    "\n",
    "tar = tarfile.open(\"/kaggle/input/brats-2021-task1/BraTS2021_Training_Data.tar\")\n",
    "tar.extractall(\".data\")\n",
    "tar.close()\n",
    "\n",
    "tar = tarfile.open(\"/kaggle/input/brats-2021-task1/BraTS2021_00495.tar\")\n",
    "tar.extractall(\"./data\")\n",
    "tar.close()\n",
    "\n",
    "tar = tarfile.open(\"/kaggle/input/brats-2021-task1/BraTS2021_00621.tar\")\n",
    "tar.extractall(\"./data\", )\n",
    "tar.close()\n",
    "\n",
    "img_id = \"01281\"\n",
    "plt.figure(figsize=(18, 5))\n",
    "for i, nii in enumerate([f'./data/BraTS2021_{img_id}/BraTS2021_{img_id}_{s_type}.nii.gz' for s_type in [\"flair\", \"t1\", \"t1ce\", \"t2\", \"seg\"]]):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    image=nib.load(nii).get_fdata()\n",
    "    plt.title(nii.rsplit(\"_\", 1)[1].split(\".\", 1)[0], fontweight=\"bold\")\n",
    "    plt.axis(False)\n",
    "    plt.imshow(image[:, :, 80], cmap=\"bone\")\n",
    "plt.tight_layout()    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e5efbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T10:45:57.848319Z",
     "iopub.status.busy": "2021-08-25T10:45:57.847358Z",
     "iopub.status.idle": "2021-08-25T10:45:58.563814Z",
     "shell.execute_reply": "2021-08-25T10:45:58.562654Z",
     "shell.execute_reply.started": "2021-08-25T10:06:48.838054Z"
    },
    "papermill": {
     "duration": 0.761415,
     "end_time": "2021-08-25T10:45:58.563946",
     "exception": false,
     "start_time": "2021-08-25T10:45:57.802531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls ./data/BraTS2021_00000/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf3c66a",
   "metadata": {
    "papermill": {
     "duration": 25.484467,
     "end_time": "2021-08-25T10:46:24.064006",
     "exception": false,
     "start_time": "2021-08-25T10:45:58.579539",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Dataset organization in subforders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33493ae6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T10:46:24.104167Z",
     "iopub.status.busy": "2021-08-25T10:46:24.103379Z",
     "iopub.status.idle": "2021-08-25T10:46:25.060518Z",
     "shell.execute_reply": "2021-08-25T10:46:25.060013Z",
     "shell.execute_reply.started": "2021-08-25T10:06:49.605710Z"
    },
    "papermill": {
     "duration": 0.980426,
     "end_time": "2021-08-25T10:46:25.060673",
     "exception": false,
     "start_time": "2021-08-25T10:46:24.080247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "Path_brats= './data/BraTS2021_'\n",
    "post_data='./post_process_data'\n",
    "final_models='./final_models'\n",
    "os.mkdir(post_data)\n",
    "os.mkdir(final_models)\n",
    "\n",
    "!ls ./data/ | awk -F'[_]' '{print $2}' > test.txt\n",
    "post_data='./post_process_data/'\n",
    "with open('./test.txt') as f:\n",
    "    for linea in f:\n",
    "        path_dest=post_data+linea\n",
    "        path_dest=path_dest.replace('\\n','')\n",
    "        if os.path.isdir(path_dest) != True:\n",
    "            os.mkdir(path_dest)\n",
    "        create_path_brats=Path_brats+linea+'/*'\n",
    "        for name in sorted(glob.glob(create_path_brats.replace('\\n',''))):        \n",
    "            shutil.move(name,path_dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead7da26",
   "metadata": {
    "papermill": {
     "duration": 0.013972,
     "end_time": "2021-08-25T10:46:25.089364",
     "exception": false,
     "start_time": "2021-08-25T10:46:25.075392",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Preparing dataset and model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95738308",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T10:46:25.130480Z",
     "iopub.status.busy": "2021-08-25T10:46:25.129956Z",
     "iopub.status.idle": "2021-08-25T10:46:25.133953Z",
     "shell.execute_reply": "2021-08-25T10:46:25.133546Z",
     "shell.execute_reply.started": "2021-08-25T10:06:54.007900Z"
    },
    "papermill": {
     "duration": 0.03079,
     "end_time": "2021-08-25T10:46:25.134058",
     "exception": false,
     "start_time": "2021-08-25T10:46:25.103268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Data_Concatenate(Input_Data):\n",
    "    counter=0\n",
    "    Output= []\n",
    "    for i in range(5):\n",
    "        print('$')\n",
    "        c=0\n",
    "        counter=0\n",
    "        for ii in range(len(Input_Data)):\n",
    "            if (counter != len(Input_Data)):\n",
    "                a= Input_Data[counter][:,:,:,i]\n",
    "                #print('a={}'.format(a.shape))\n",
    "                b= Input_Data[counter+1][:,:,:,i]\n",
    "                #print('b={}'.format(b.shape))\n",
    "                if(counter==0):\n",
    "                    c= np.concatenate((a, b), axis=0)\n",
    "                    print('c1={}'.format(c.shape))\n",
    "                    counter= counter+2\n",
    "                else:\n",
    "                    c1= np.concatenate((a, b), axis=0)\n",
    "                    c= np.concatenate((c, c1), axis=0)\n",
    "                    print('c2={}'.format(c.shape))\n",
    "                    counter= counter+2\n",
    "        c= c[:,:,:,np.newaxis]\n",
    "        Output.append(c)\n",
    "    return Output\n",
    "    \n",
    "def launch_model(Input_Data,code,model):\n",
    "    \n",
    "    InData= Data_Concatenate(Input_Data)\n",
    "    AIO= concatenate(InData, axis=3)\n",
    "    AIO=np.array(AIO,dtype='float32')\n",
    "    TR=np.array(AIO[:,:,:,1],dtype='float32')\n",
    "    TRL=np.array(AIO[:,:,:,4],dtype='float32')\n",
    "    X_train , X_test, Y_train, Y_test = train_test_split(TR, TRL, test_size=0.15, random_state=32)\n",
    "    AIO=TRL=0\n",
    "\n",
    "    # Fitting the model over the data\n",
    "    print(\"-- Fitting the model over the data --\")\n",
    "    history = model.fit(X_train,Y_train,batch_size=32,epochs=20,validation_split=0.20,verbose=1,initial_epoch=0)\n",
    "    \n",
    "    # Evaluating the model on the training and testing data \n",
    "    print(\"-- Evaluating the model on the training and testing data --\")\n",
    "    model.evaluate(x=X_train, y=Y_train, batch_size=32 , verbose=1, sample_weight=None, steps=None)\n",
    "    model.evaluate(x=X_test, y=Y_test, batch_size=32, verbose=1, sample_weight=None, steps=None)    \n",
    "    \n",
    "    # Plotting the Graphs of Accuracy, Dice_coefficient, Loss at each epoch on Training and Testing data\n",
    "    print(\"-- Plotting the Graphs of Accuracy, Dice_coefficient, Loss at each epoch on Training and Testing data --\")\n",
    "    Accuracy_Graph(history)\n",
    "    Dice_coefficient_Graph(history)\n",
    "    Loss_Graph(history)\n",
    "               \n",
    "    model.save('./final_models/BraTs2021_'+code+'.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe07a4b",
   "metadata": {
    "papermill": {
     "duration": 0.01362,
     "end_time": "2021-08-25T10:46:25.161696",
     "exception": false,
     "start_time": "2021-08-25T10:46:25.148076",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Launch model**\n",
    "\n",
    "* top_limit_number = Number of loops that we take.\n",
    "* split_number = Number of elements that we take for the look\n",
    "* init_counter = Loop local counter\n",
    "* inside_split_countert = Loop global counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7c6061",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T10:46:25.202258Z",
     "iopub.status.busy": "2021-08-25T10:46:25.201427Z",
     "iopub.status.idle": "2021-08-25T12:10:08.575048Z",
     "shell.execute_reply": "2021-08-25T12:10:08.575530Z",
     "shell.execute_reply.started": "2021-08-25T10:06:54.033950Z"
    },
    "papermill": {
     "duration": 5023.400045,
     "end_time": "2021-08-25T12:10:08.575683",
     "exception": false,
     "start_time": "2021-08-25T10:46:25.175638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "Path= './post_process_data'\n",
    "p=os.listdir(Path)\n",
    "Input_Data= []\n",
    "\n",
    "\n",
    "def Data_Preprocessing(modalities_dir):\n",
    "    all_modalities = []    \n",
    "    for modality in modalities_dir:      \n",
    "        nifti_file   = nib.load(modality)\n",
    "        brain_numpy  = np.asarray(nifti_file.dataobj)    \n",
    "        all_modalities.append(brain_numpy)\n",
    "    brain_affine   = nifti_file.affine\n",
    "    all_modalities = np.array(all_modalities)\n",
    "    all_modalities = np.rint(all_modalities).astype(np.int16)\n",
    "    all_modalities = all_modalities[:, :, :, :]\n",
    "    all_modalities = np.transpose(all_modalities)\n",
    "    return all_modalities\n",
    "\n",
    "top_limit_number = 15\n",
    "split_number = 20\n",
    "init_counter=0\n",
    "inside_split_countert=1\n",
    "total_count_img, partial_count_img = len(p), int(len(p)/split_number)\n",
    "\n",
    "for i in tqdm(p):\n",
    "    if (int(init_counter*inside_split_countert) == total_count_img) or (int(top_limit_number*split_number)==int(init_counter*inside_split_countert)):\n",
    "        print(\"Launch Final model.\")\n",
    "        launch_model(Input_Data,str(init_counter), model)\n",
    "        del(Input_Data)\n",
    "        gc.collect()\n",
    "        break    \n",
    "    if (init_counter == split_number):\n",
    "        print(\"Launch model :\"+str(init_counter*inside_split_countert))\n",
    "        launch_model(Input_Data,str(init_counter*inside_split_countert),model)\n",
    "        del(Input_Data)\n",
    "        gc.collect()\n",
    "        Input_Data= []\n",
    "        inside_split_countert=inside_split_countert+1\n",
    "        init_counter=0\n",
    "    create_path_post=Path+'/'+i+'/*'\n",
    "    \n",
    "    for name in sorted(glob.glob(create_path_post.replace('\\n',''))):\n",
    "        os.system('gunzip ' + name)\n",
    "    brain_dir = os.path.normpath(Path+'/'+i+'/')\n",
    "    flair     = glob.glob(os.path.join(brain_dir, '*_flair*.nii'))\n",
    "    t1        = glob.glob(os.path.join(brain_dir, '*_t1*.nii'))\n",
    "    t1ce      = glob.glob(os.path.join(brain_dir, '*_t1ce*.nii'))\n",
    "    t2        = glob.glob(os.path.join(brain_dir, '*_t2*.nii'))\n",
    "    gt        = glob.glob( os.path.join(brain_dir, '*_seg*.nii'))\n",
    "    modalities_dir = [flair[0], t1[0], t1ce[0], t2[0], gt[0]]\n",
    "    P_Data = Data_Preprocessing(modalities_dir)\n",
    "    Input_Data.append(P_Data)\n",
    "    shutil.rmtree(Path+'/'+i)\n",
    "    init_counter = init_counter + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5256.307323,
   "end_time": "2021-08-25T12:10:17.436021",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-25T10:42:41.128698",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
